{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using PyTorch Lightning for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from module import ImageClassificationModule\n",
    "\n",
    "transformers.utils.logging.set_verbosity_error()  # suppress image processor warning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a model checkpoint with PyTorch Lightning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to load checkpoints directly into LightningModules to either continue training, or for inference. Here, we load the model with the expectation that we will use it to predict on images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = os.listdir(\"checkpoints\")\n",
    "print(f\"We will use the {checkpoints[0]} checkpoint for inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "model = ImageClassificationModule.load_from_checkpoint(f\"checkpoints/{checkpoints[0]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LightningModule's .predict_step to classify on input"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know from our `visualizing_logs_metrics_cost.ipynb` notebook that the models should produce reasonably accurate results, as each model had a final validation accuracy of around 80% (not ideal).\n",
    "\n",
    "Below, we read in known positive sequences taken from the test dataset, and then pass that sequence to our LightningModules's `predict_step` several times to observe results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = model.model.config.id2label\n",
    "test_dataset = load_dataset(\"cifar100\", cache_dir=\"data\", split=\"test\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab our label mapping to check our prediction ID and actual label tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_label_map = pd.read_csv(\"data/cifar_fine_label_map.csv\", index_col=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's grab a small sample of just 15 images and use the model to predict what those images might be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = test_dataset[:15]\n",
    "results = []\n",
    "\n",
    "for idx, image in enumerate(images[\"img\"]):\n",
    "    pred = model.predict_step(image)\n",
    "    pred_label = cifar_label_map.iloc[pred.argmax(-1).item()].item().strip()\n",
    "    truth_label = cifar_label_map.iloc[images[\"fine_label\"][idx]].item().strip()\n",
    "    truthiness = pred_label == truth_label\n",
    "    results.append(truthiness)\n",
    "    print(f\"Our finetuned model classifies this image as: {pred_label}. The actual label is: {truth_label}. The classification is {truthiness}.\")\n",
    "\n",
    "trues = [i for i in results if i]\n",
    "print(f\"\\nThe accuracy for this random sample is {round((len(trues) / len(results)) * 100, 4)}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our output is below our validation accuracy; however, this is for a random sample - and not a stratified sampling based on the labels.\n",
    "\n",
    "The overall accuracy of each training checkpoint isn't optimal - as an accuracy of around 80% isn't desirable for production.  Additional steps can be taken to improve the accuracy - such as replacing classifier layers and freezing the encoder layers. However, such tasks are outside of the scope of this work and warrant further experimentation to create a better performing model ðŸ™‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
